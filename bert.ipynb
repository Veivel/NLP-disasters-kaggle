{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP with Disasters Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Stuff yada yada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "from sklearn import feature_extraction, model_selection, metrics\n",
    "from sklearn import naive_bayes, ensemble, tree, linear_model\n",
    "import xgboost\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "DUMMY_RUN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_len = train_df[train_df['target']==1]['text'].str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = nltk.stem.PorterStemmer()\n",
    "\n",
    "def clean(text):\n",
    "    new_text = remove_links(text.lower())\n",
    "    new_text = re.sub('[^a-zA-Z ]', '', new_text)\n",
    "    new_text = stemmer.stem(new_text)\n",
    "    return new_text\n",
    "\n",
    "def remove_links(text):\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url.sub(r'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = [clean(tweet) for tweet in train_df['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def bert_tokenize(text):\n",
    "  encoded_input = tokenizer(text, return_tensors='pt')\n",
    "  output = model(**encoded_input)\n",
    "  return output\n",
    "\n",
    "# X = [bert_tokenize(tweet) for tweet in tweets]\n",
    "y = train_df['target']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.1915,  0.4895, -0.2911,  ..., -0.0122,  0.1492,  0.1083],\n",
      "         [ 0.1957,  0.3231, -0.6850,  ...,  0.2040,  0.8128,  0.1034],\n",
      "         [ 0.5748,  0.5154, -0.1396,  ...,  0.1337,  0.3736,  0.1703],\n",
      "         [-0.1849,  0.2354, -0.4561,  ...,  0.9887,  0.8068, -0.1834],\n",
      "         [ 0.8280,  0.0850, -0.2614,  ..., -0.2030, -0.5610, -0.4148]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-7.8596e-01, -2.3175e-01,  4.5795e-01,  5.5659e-01, -1.9156e-01,\n",
      "         -1.2896e-01,  7.4936e-01,  1.5217e-01,  7.7843e-02, -9.9923e-01,\n",
      "          2.7356e-01,  3.2724e-01,  9.6944e-01, -2.2192e-01,  8.6324e-01,\n",
      "         -4.6482e-01, -1.1516e-01, -4.8018e-01,  2.6196e-01, -6.2988e-01,\n",
      "          4.5500e-01,  7.5136e-01,  5.8449e-01,  2.0188e-01,  3.3682e-01,\n",
      "          4.1782e-01, -4.5399e-01,  8.5607e-01,  9.1431e-01,  6.0741e-01,\n",
      "         -5.6835e-01,  9.5383e-02, -9.7337e-01, -7.3753e-02,  4.0617e-01,\n",
      "         -9.6457e-01,  1.4618e-01, -6.6786e-01,  1.4640e-01,  6.9979e-02,\n",
      "         -8.0579e-01,  1.8612e-01,  9.9051e-01, -3.0284e-01, -6.5457e-02,\n",
      "         -2.2957e-01, -9.9929e-01,  1.9193e-01, -7.8360e-01, -3.9203e-01,\n",
      "         -2.5351e-01, -3.6362e-01,  9.0752e-02,  2.8855e-01,  2.9502e-01,\n",
      "          1.9619e-02, -1.4223e-01,  3.9012e-02, -1.7734e-02, -4.5048e-01,\n",
      "         -5.2253e-01,  2.5223e-01,  1.3024e-01, -8.0536e-01, -7.2549e-02,\n",
      "         -4.8817e-01,  4.1415e-02, -6.5325e-02,  7.5597e-02, -1.0911e-01,\n",
      "          7.2559e-01,  8.7789e-02,  4.1867e-01, -6.6008e-01, -2.9312e-01,\n",
      "          1.0758e-01, -3.7439e-01,  9.9998e-01, -3.3109e-01, -9.6091e-01,\n",
      "         -4.3347e-01, -2.5832e-01,  1.9353e-01,  5.7009e-01, -5.3693e-01,\n",
      "         -9.9990e-01,  1.4453e-01, -3.9186e-02, -9.7732e-01,  6.8588e-02,\n",
      "          1.7954e-01, -1.1590e-01, -6.3696e-01,  2.8000e-01, -3.0564e-02,\n",
      "         -1.1310e-01, -4.5537e-02,  4.1544e-01, -2.6418e-02, -1.2598e-01,\n",
      "         -6.9774e-02, -7.3683e-02,  5.2428e-02, -1.8343e-01,  1.3310e-01,\n",
      "         -2.6214e-01, -3.5448e-01, -5.7200e-03, -1.7457e-01,  5.7365e-01,\n",
      "          2.2533e-01, -1.6250e-01,  2.2228e-01, -9.1502e-01,  5.4026e-01,\n",
      "         -1.3945e-01, -9.6453e-01, -3.1035e-01, -9.7328e-01,  5.3484e-01,\n",
      "          1.9451e-01, -5.8570e-02,  9.3250e-01,  5.3565e-01,  1.6521e-01,\n",
      "          5.7715e-02,  2.2595e-01, -9.9999e-01, -4.0294e-01,  9.1624e-02,\n",
      "          1.9630e-01,  1.7169e-02, -9.5992e-01, -8.9571e-01,  4.3267e-01,\n",
      "          9.1467e-01, -2.5943e-02,  9.8677e-01, -8.6436e-02,  8.6519e-01,\n",
      "          2.0378e-01, -6.3231e-02, -1.6511e-01, -2.5809e-01,  1.2245e-01,\n",
      "          2.6202e-02, -5.6187e-01,  9.3773e-02,  6.6729e-02, -1.2957e-01,\n",
      "          1.3506e-01, -1.5097e-01,  2.3265e-01, -8.6143e-01, -3.2831e-01,\n",
      "          8.9048e-01,  2.5725e-01,  3.3403e-01,  6.3050e-01, -1.2005e-01,\n",
      "         -1.4995e-01,  6.5648e-01,  2.8557e-01,  1.9461e-01,  9.0677e-03,\n",
      "          2.5509e-01, -4.3898e-01,  2.9016e-01, -7.0505e-01,  1.2646e-01,\n",
      "          3.2664e-01, -1.0517e-01,  5.2543e-01, -9.5989e-01, -1.0946e-01,\n",
      "          3.1053e-01,  9.6852e-01,  6.0233e-01,  9.9749e-02,  9.3711e-02,\n",
      "         -1.0761e-01,  1.8305e-01, -8.8577e-01,  9.5736e-01, -7.8165e-02,\n",
      "          1.6555e-01,  5.7908e-01, -1.7189e-01, -7.7250e-01, -4.9720e-01,\n",
      "          6.6069e-01, -1.2903e-01, -8.0863e-01,  1.2532e-01, -3.5029e-01,\n",
      "         -3.1904e-01,  3.7205e-01,  3.8938e-01, -2.1092e-01, -2.6552e-01,\n",
      "          1.3271e-01,  8.6476e-01,  9.1528e-01,  7.1151e-01, -5.7708e-01,\n",
      "          4.6659e-01, -8.0775e-01, -3.1255e-01,  6.8308e-02,  1.6707e-01,\n",
      "          1.0798e-01,  9.8388e-01,  2.4557e-01, -9.5342e-02, -8.9712e-01,\n",
      "         -9.7232e-01, -1.1538e-01, -8.5992e-01,  8.8809e-02, -4.6208e-01,\n",
      "          2.1466e-01,  6.3438e-01, -1.4163e-01,  2.6088e-01, -9.5303e-01,\n",
      "         -7.1252e-01,  2.7987e-01, -1.3895e-01,  2.8208e-01, -2.2027e-01,\n",
      "          5.5541e-01, -1.9819e-01, -4.6068e-01,  7.5794e-01,  7.9503e-01,\n",
      "          5.3063e-01, -5.8692e-01,  7.1478e-01, -1.9615e-01,  7.8936e-01,\n",
      "         -3.9526e-01,  9.2723e-01, -1.9806e-01,  5.0281e-01, -8.8264e-01,\n",
      "          4.3573e-01, -8.4326e-01,  2.7413e-01,  1.5617e-02, -6.9470e-01,\n",
      "         -2.3358e-01,  2.8310e-01,  2.0674e-01,  8.7790e-01, -3.6007e-01,\n",
      "          9.8722e-01, -6.1923e-01, -9.0887e-01,  5.1285e-01,  2.3317e-03,\n",
      "         -9.7142e-01, -2.0448e-01,  5.2085e-02, -6.9977e-01, -2.1359e-01,\n",
      "         -1.6557e-01, -9.2176e-01,  8.2058e-01,  5.4790e-02,  9.5756e-01,\n",
      "         -2.6201e-02, -8.3540e-01, -3.1562e-01, -8.1414e-01, -2.5004e-01,\n",
      "         -4.7741e-02,  6.0889e-01, -2.1985e-01, -9.1437e-01,  3.1865e-01,\n",
      "          4.1069e-01,  3.0784e-01,  5.7075e-01,  9.8779e-01,  9.9048e-01,\n",
      "          9.6362e-01,  8.0504e-01,  7.7127e-01, -5.8942e-01, -1.0175e-01,\n",
      "          9.9961e-01, -4.8193e-01, -9.9955e-01, -8.7971e-01, -3.3896e-01,\n",
      "          1.3841e-01, -9.9999e-01, -4.4393e-02,  1.2218e-01, -8.7083e-01,\n",
      "         -4.0002e-01,  9.6377e-01,  9.6776e-01, -9.9997e-01,  7.4629e-01,\n",
      "          8.9320e-01, -3.6046e-01,  2.4010e-01, -1.1154e-01,  9.5177e-01,\n",
      "          1.3722e-01,  3.1658e-01, -3.4850e-02,  2.5193e-01,  1.6785e-01,\n",
      "         -7.0383e-01,  4.3376e-01,  3.7002e-01,  2.5979e-01,  4.3909e-02,\n",
      "         -5.5939e-01, -8.7257e-01, -1.4907e-02, -3.5488e-02, -2.8019e-01,\n",
      "         -9.0874e-01,  2.8404e-02, -2.8190e-01,  5.3241e-01, -2.0464e-02,\n",
      "          1.4432e-02, -7.0082e-01,  4.6782e-02, -7.4995e-01,  1.5252e-01,\n",
      "          4.1853e-01, -8.7140e-01, -5.1352e-01,  2.1829e-01, -4.4592e-01,\n",
      "          4.0829e-01, -9.1052e-01,  9.4141e-01, -1.5802e-01, -1.5352e-02,\n",
      "          9.9998e-01, -3.3509e-01, -7.6130e-01,  2.3243e-01,  1.0129e-01,\n",
      "          2.4553e-01,  9.9995e-01,  3.9505e-01, -9.5472e-01, -2.8053e-01,\n",
      "          1.6112e-01, -3.4817e-01, -3.1323e-01,  9.9031e-01, -1.3222e-01,\n",
      "          2.9936e-01,  4.6971e-01,  9.4712e-01, -9.7631e-01, -1.0509e-01,\n",
      "         -8.5142e-01, -9.3611e-01,  9.2157e-01,  8.7588e-01, -1.5293e-01,\n",
      "         -3.3703e-01,  1.7006e-02,  3.2348e-01,  6.2913e-02, -9.2519e-01,\n",
      "          5.0343e-01,  3.6154e-01, -7.8770e-02,  8.4481e-01, -7.2364e-01,\n",
      "         -3.0225e-01,  2.9126e-01,  1.0735e-01,  3.5876e-01, -3.3317e-01,\n",
      "          3.1305e-01, -2.4018e-02,  1.1948e-01, -1.0129e-01, -2.1105e-01,\n",
      "         -9.5018e-01, -7.5435e-02,  9.9994e-01,  1.5366e-01, -4.3962e-01,\n",
      "         -1.7118e-01,  3.3197e-02, -3.8840e-01,  2.3729e-01,  2.4939e-01,\n",
      "         -1.4604e-01, -6.5179e-01, -1.9238e-01, -8.8430e-01, -9.6967e-01,\n",
      "          5.0995e-01,  4.2683e-02, -1.3812e-01,  9.9469e-01,  1.6301e-01,\n",
      "          6.2530e-02, -7.9598e-02,  2.9722e-01, -8.6678e-02,  3.4176e-01,\n",
      "         -4.2883e-01,  9.4359e-01, -1.2367e-01,  2.5874e-01,  7.2256e-01,\n",
      "          2.1265e-01, -1.7010e-01, -5.4671e-01, -1.9919e-02, -8.7208e-01,\n",
      "          8.3922e-02, -8.9778e-01,  9.1376e-01, -3.1032e-01,  1.8658e-01,\n",
      "         -1.1083e-02, -3.2122e-01,  9.9997e-01,  2.6847e-01,  4.6978e-01,\n",
      "         -4.1343e-01,  7.7415e-01, -5.5728e-01, -5.7837e-01, -2.8969e-01,\n",
      "          6.5211e-02,  4.2612e-01, -1.5002e-01,  6.3694e-02, -9.3761e-01,\n",
      "         -4.1833e-01, -2.2727e-01, -9.4983e-01, -9.7987e-01,  4.6227e-01,\n",
      "          6.2504e-01, -2.8898e-02,  8.2054e-03, -5.7481e-01, -4.7315e-01,\n",
      "          8.6268e-02, -1.6755e-02, -8.7768e-01,  5.6100e-01, -1.0984e-01,\n",
      "          3.5435e-01, -1.0819e-01,  3.0057e-01, -4.8164e-01,  8.1328e-01,\n",
      "          6.7535e-01,  2.1259e-01,  1.2239e-01, -6.4312e-01,  7.0495e-01,\n",
      "         -7.3025e-01,  2.9418e-01, -6.8225e-02,  9.9999e-01, -3.5599e-01,\n",
      "         -2.4066e-01,  5.6129e-01,  6.2455e-01,  6.7717e-02,  1.0245e-01,\n",
      "         -4.4464e-01,  1.6917e-02,  5.1915e-01,  3.6769e-01, -7.0281e-01,\n",
      "         -1.3518e-01,  4.5593e-01, -5.1346e-01, -5.6355e-01,  6.3544e-01,\n",
      "         -1.8337e-02,  5.2919e-02,  1.4244e-01, -6.5374e-02,  9.9607e-01,\n",
      "         -9.1154e-02, -7.3885e-02, -3.4171e-01,  1.3832e-01, -1.6424e-01,\n",
      "         -4.8356e-01,  9.9979e-01,  3.0965e-01, -2.1994e-01, -9.7832e-01,\n",
      "          2.1476e-01, -8.0964e-01,  9.7790e-01,  7.1196e-01, -7.3756e-01,\n",
      "          4.2923e-01,  1.8999e-01, -4.2753e-02,  6.7483e-01, -2.6817e-02,\n",
      "         -1.9061e-02,  1.0334e-01,  1.1183e-02,  9.3278e-01, -2.8681e-01,\n",
      "         -9.2693e-01, -3.2411e-01,  2.8236e-01, -9.3968e-01,  6.5047e-01,\n",
      "         -3.7148e-01, -6.0751e-02, -1.2229e-01,  3.1026e-01,  6.0691e-01,\n",
      "         -1.4605e-01, -9.6064e-01, -4.6543e-02, -3.1095e-02,  9.2934e-01,\n",
      "          8.7559e-02, -2.8347e-01, -8.3225e-01, -5.0968e-01, -1.7771e-01,\n",
      "          3.6417e-01, -8.8394e-01,  9.4387e-01, -9.6009e-01,  4.4076e-01,\n",
      "          9.9974e-01,  2.1668e-01, -6.9030e-01,  2.8985e-02, -2.7377e-01,\n",
      "          5.6375e-02,  4.1562e-01,  3.5745e-01, -9.2338e-01, -1.6674e-01,\n",
      "         -4.2240e-02,  1.4217e-01, -1.1566e-01,  2.6563e-01,  4.3095e-01,\n",
      "          8.1408e-02, -2.5071e-01, -3.8248e-01,  8.9341e-03,  2.6842e-01,\n",
      "          6.5533e-01, -1.6052e-01, -5.8629e-02,  1.0720e-01, -4.7044e-02,\n",
      "         -8.1370e-01, -1.9838e-01, -1.1709e-01, -9.1083e-01,  5.1283e-01,\n",
      "         -9.9998e-01, -4.5136e-01, -5.9066e-01, -1.6287e-01,  6.4044e-01,\n",
      "          2.1784e-01, -7.2302e-02, -5.6692e-01,  3.5319e-01,  8.0211e-01,\n",
      "          6.0330e-01, -9.8822e-02,  7.1993e-02, -5.5997e-01,  5.1733e-02,\n",
      "         -2.4709e-02,  1.6175e-01,  2.2620e-01,  6.4358e-01, -7.5981e-02,\n",
      "          9.9999e-01,  4.9927e-02, -4.1668e-01, -9.1657e-01,  1.2420e-01,\n",
      "         -1.4609e-01,  9.9724e-01, -8.3639e-01, -8.9878e-01,  9.6588e-02,\n",
      "         -3.1146e-01, -6.7353e-01,  1.2955e-01, -7.1889e-02, -4.7729e-01,\n",
      "          1.2795e-01,  8.9170e-01,  7.9217e-01, -2.8101e-01,  3.4854e-01,\n",
      "         -1.3949e-01, -3.4241e-01, -5.2630e-02, -4.6885e-01,  9.6969e-01,\n",
      "         -9.6727e-02,  8.5661e-01,  2.9665e-01,  2.7809e-02,  9.2036e-01,\n",
      "          1.1408e-01,  4.3427e-01, -1.4563e-02,  9.9983e-01,  1.4056e-01,\n",
      "         -8.3252e-01,  4.4122e-01, -9.6387e-01, -3.3219e-02, -9.2105e-01,\n",
      "          1.3580e-01, -4.9750e-02,  8.3268e-01, -9.3667e-02,  9.3004e-01,\n",
      "          4.9569e-01,  1.2911e-04,  2.2050e-02,  6.4486e-01,  2.5293e-01,\n",
      "         -8.4408e-01, -9.7168e-01, -9.7174e-01,  2.5564e-01, -3.2819e-01,\n",
      "          2.2356e-02,  2.0112e-01,  1.4961e-01,  2.3477e-01,  2.3702e-01,\n",
      "         -9.9972e-01,  8.7088e-01,  2.7328e-01, -3.9192e-01,  9.3621e-01,\n",
      "          1.6174e-01,  2.6923e-01,  1.2851e-01, -9.6597e-01, -9.2011e-01,\n",
      "         -2.3274e-01, -1.6963e-01,  5.5626e-01,  4.5351e-01,  7.2714e-01,\n",
      "          2.1274e-01, -3.9496e-01, -1.5326e-01,  5.5195e-01, -5.5061e-01,\n",
      "         -9.7946e-01,  2.4580e-01,  2.2836e-01, -9.3805e-01,  9.0962e-01,\n",
      "         -5.9178e-01, -6.0404e-02,  6.0961e-01,  3.0122e-01,  8.4239e-01,\n",
      "          5.5554e-01,  3.6284e-01,  3.7181e-02,  2.5712e-01,  8.1360e-01,\n",
      "          8.9278e-01,  9.7242e-01,  2.7302e-01,  6.3153e-01,  2.0090e-01,\n",
      "          2.0636e-01,  4.1136e-01, -8.7665e-01,  2.0547e-02, -7.5983e-02,\n",
      "          1.2268e-01,  1.2646e-01, -7.0878e-02, -9.1655e-01,  2.0997e-01,\n",
      "         -9.5815e-02,  2.1126e-01, -1.8487e-01,  2.4400e-01, -2.1655e-01,\n",
      "         -7.3249e-02, -5.3592e-01, -2.5049e-01,  4.0312e-01,  2.2140e-01,\n",
      "          8.3341e-01,  2.8216e-02,  6.8161e-02, -5.1984e-01, -3.5820e-02,\n",
      "          4.6144e-01, -8.2663e-01,  8.3937e-01,  7.2569e-02,  5.0743e-01,\n",
      "         -3.4645e-01, -1.5952e-01,  2.3953e-01, -4.3272e-01, -2.9146e-01,\n",
      "         -2.2303e-01, -6.2390e-01,  7.7133e-01, -1.8986e-01, -3.2380e-01,\n",
      "         -2.1279e-01,  4.4733e-01,  2.2073e-01,  8.4751e-01,  2.9058e-01,\n",
      "          4.6199e-02, -1.6118e-01, -1.0387e-01,  2.1567e-01, -5.3807e-02,\n",
      "         -9.9974e-01,  3.4062e-01,  3.0701e-01, -3.8534e-01,  1.0563e-01,\n",
      "         -4.1076e-01, -1.0506e-01, -9.3336e-01,  2.5816e-02, -1.1137e-01,\n",
      "         -3.8945e-01, -4.4255e-01, -3.1593e-01,  2.8677e-01,  3.0821e-01,\n",
      "          2.4887e-02,  7.7890e-01,  3.2383e-01,  6.2353e-01,  3.9215e-01,\n",
      "          4.5299e-01, -5.7430e-01,  8.1084e-01]], grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n"
     ]
    }
   ],
   "source": [
    "print(bert_tokenize(\"i hate everything\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_classifiers = {\n",
    "    'xgb': xgboost.XGBClassifier(),\n",
    "    'gaussian_nb': naive_bayes.GaussianNB(), # why nan?\n",
    "    'multi_nb': naive_bayes.MultinomialNB(),\n",
    "    # 'rforest': ensemble.RandomForestClassifier(),\n",
    "    'decision_tree': tree.DecisionTreeClassifier(),\n",
    "    'log_reg': linear_model.LogisticRegression()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb score: 0.5582559320381396\n",
      "gaussian_nb score: 0.5485410305236484\n",
      "multi_nb score: 0.5227933836236834\n",
      "decision_tree score: 0.5585185715653885\n",
      "log_reg score: 0.5606208957181302\n"
     ]
    }
   ],
   "source": [
    "if DUMMY_RUN:\n",
    "    for name in dict_classifiers:\n",
    "        clf = dict_classifiers[name]\n",
    "        scores = model_selection.cross_val_score(clf, X, y)\n",
    "        print(f\"{name} score: {np.average(scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting & Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choice = 'multi_nb'\n",
    "clf = dict_classifiers[choice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not DUMMY_RUN:\n",
    "    # Importing and pre-processing test data\n",
    "    test_df = pd.read_csv('test.csv')\n",
    "    test_tweets = [clean(tweet) for tweet in test_df['text']]\n",
    "    X_test = cv.transform(test_tweets)\n",
    "    \n",
    "    # Fit & forecast\n",
    "    clf.fit(X, y)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Export\n",
    "    out = pd.DataFrame(\n",
    "        data={'id': test_df['id'],\n",
    "              'target': y_pred},\n",
    "    )\n",
    "    out.to_csv('results.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
